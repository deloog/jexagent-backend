from typing import Dict, Set, List, Optional
import socketio
import asyncio
import time
import os
from collections import defaultdict, deque
from contextlib import suppress

# âœ… Redisé…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒå¯ç”¨ï¼‰
USE_REDIS = os.getenv("USE_REDIS_CACHE", "false").lower() == "true"

if USE_REDIS:
    import redis.asyncio as redis
    import json
    redis_client = redis.Redis(
        host=os.getenv("REDIS_HOST", "localhost"),
        port=int(os.getenv("REDIS_PORT", 6379)),
        decode_responses=True
    )
else:
    # âœ… å¼€å‘ç¯å¢ƒï¼šè¿›ç¨‹å†…ç¼“å­˜ï¼ˆå•è¿›ç¨‹éƒ¨ç½²ï¼‰
    _progress_cache: Dict[str, deque] = {}
    _completion_cache: Dict[str, dict] = {}  # â† æ–°å¢ï¼šç¼“å­˜completeäº‹ä»¶

# âœ… å…¨å±€é…ç½®
MAX_TASKS_IN_MEMORY = 10000  # æœ€å¤§ç¼“å­˜ä»»åŠ¡æ•°
CACHE_CLEANUP_DELAY = 300    # å®Œæˆå5åˆ†é’Ÿæ¸…ç†ç¼“å­˜

class SocketManager:
    """WebSocketç®¡ç†å™¨ - ç”Ÿäº§çº§å®ç°"""
    
    def __init__(self):
        # âœ… CORSé…ç½® - ç”Ÿäº§ç¯å¢ƒæ”¶ç´§
        allowed_origins = os.getenv("CORS_ORIGINS", "*")
        if allowed_origins == "*":
            print("âš ï¸ è­¦å‘Šï¼šCORSè®¾ç½®ä¸º '*'ï¼Œç”Ÿäº§ç¯å¢ƒè¯·æ”¶ç´§ï¼")
        
        self.sio = socketio.AsyncServer(
            async_mode='asgi',
            cors_allowed_origins=allowed_origins.split(",") if allowed_origins != "*" else "*",
            ping_timeout=60,
            ping_interval=25
        )
        
        # âœ… è¿æ¥ç®¡ç†
        self.connections: Dict[str, Set[str]] = {}  # task_id -> set of sid
        self.sid_to_tasks: Dict[str, Set[str]] = {}  # âœ… åå‘ç´¢å¼•ï¼šsid -> set of task_id
        
        # âœ… åºåˆ—å·ç®¡ç†ï¼ˆä½¿ç”¨Redisæˆ–å†…å­˜ï¼‰
        if USE_REDIS:
            # Redis INCR ä¿è¯åŸå­æ€§å’ŒæŒä¹…åŒ–
            self.sequence_counters = None
        else:
            self.sequence_counters: Dict[str, int] = {}
            self._seq_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)
        
        # âœ… è¿æ¥äº‹ä»¶ï¼ˆç”¨äºwait_for_connectionï¼‰
        self._connection_events: Dict[str, asyncio.Event] = {}
        
        self._register_events()
    
    def _register_events(self):
        """æ³¨å†Œæ‰€æœ‰Socket.IOäº‹ä»¶"""
        
        @self.sio.event
        async def connect(sid, environ):
            print(f"[WS] Client connected: {sid}")
        
        @self.sio.event
        async def disconnect(sid):
            print(f"[WS] Client disconnected: {sid}")
            
            # âœ… O(1)æ¸…ç†ï¼šä½¿ç”¨åå‘ç´¢å¼•
            task_ids = self.sid_to_tasks.get(sid, set())
            for task_id in task_ids:
                if task_id in self.connections:
                    self.connections[task_id].discard(sid)
                    if not self.connections[task_id]:
                        del self.connections[task_id]
            
            # æ¸…ç†åå‘ç´¢å¼•
            if sid in self.sid_to_tasks:
                del self.sid_to_tasks[sid]
        
        @self.sio.event
        async def join_task(sid, data):
            """å®¢æˆ·ç«¯åŠ å…¥ä»»åŠ¡æˆ¿é—´"""
            task_id = data.get('task_id')
            if not task_id:
                return
            
            # æ·»åŠ åˆ°è¿æ¥æ˜ å°„
            if task_id not in self.connections:
                self.connections[task_id] = set()
            self.connections[task_id].add(sid)
            
            # âœ… ç»´æŠ¤åå‘ç´¢å¼•
            if sid not in self.sid_to_tasks:
                self.sid_to_tasks[sid] = set()
            self.sid_to_tasks[sid].add(task_id)
            
            print(f"[WS] Client {sid} joined task {task_id}")
            print(f"[WS] Active connections for {task_id}: {len(self.connections[task_id])}")
            
            # âœ… è§¦å‘è¿æ¥äº‹ä»¶
            if task_id not in self._connection_events:
                self._connection_events[task_id] = asyncio.Event()
            self._connection_events[task_id].set()
            
            # âœ… å‘é€completeäº‹ä»¶ï¼ˆå¦‚æœä»»åŠ¡å·²å®Œæˆä¸”å®¢æˆ·ç«¯åˆšè¿æ¥ï¼‰
            if not USE_REDIS and task_id in _completion_cache:
                print(f"[WS] é‡å‘completeäº‹ä»¶ç»™æ–°è¿æ¥: {sid}")
                await self.sio.emit('complete', _completion_cache[task_id], room=sid)
            
            await self.sio.emit('joined', {'task_id': task_id}, room=sid)
        
        @self.sio.event
        async def ping(sid):
            """å¿ƒè·³æ£€æµ‹"""
            await self.sio.emit('pong', room=sid)
    
    async def _get_next_sequence_id(self, task_id: str) -> int:
        """è·å–ä¸‹ä¸€ä¸ªåºåˆ—å·ï¼ˆRedisæˆ–å†…å­˜ï¼‰"""
        if USE_REDIS:
            # âœ… Redis INCRï¼šåŸå­æ“ä½œ + æŒä¹…åŒ–
            return await redis_client.incr(f"seq:{task_id}")
        else:
            # âœ… å†…å­˜é”ä¿æŠ¤
            async with self._seq_locks[task_id]:
                if task_id not in self.sequence_counters:
                    self.sequence_counters[task_id] = 0
                sequence_id = self.sequence_counters[task_id]
                self.sequence_counters[task_id] += 1
                return sequence_id
    
    async def emit_progress(self, task_id: str, phase: str, progress: int, message: str):
        """æ¨é€è¿›åº¦æ›´æ–° - å…ˆç¼“å­˜å†æ¨é€"""
        
        # âœ… è·å–åºåˆ—å·
        sequence_id = await self._get_next_sequence_id(task_id)
        
        # æ„å»ºè¿›åº¦é¡¹
        item = {
            "phase": phase,
            "progress": progress,
            "message": message,
            "ts": time.time(),
            "sequence_id": sequence_id,
            "task_id": task_id
        }
        
        # âœ… ç¼“å­˜è¿›åº¦
        if USE_REDIS:
            # Redis List: LPUSH + LTRIM
            await redis_client.lpush(f"progress:{task_id}", json.dumps(item))
            await redis_client.ltrim(f"progress:{task_id}", 0, 999)
        else:
            # âœ… å†…å­˜ç¼“å­˜ + LRUæ·˜æ±°
            if task_id not in _progress_cache:
                # æ£€æŸ¥å…¨å±€ä»»åŠ¡æ•°ä¸Šé™
                if len(_progress_cache) >= MAX_TASKS_IN_MEMORY:
                    print(f"âš ï¸ è¾¾åˆ°ç¼“å­˜ä¸Šé™ï¼Œæ¸…ç†æœ€æ—©çš„ä»»åŠ¡")
                    # åˆ é™¤æœ€æ—©çš„20%
                    to_remove = list(_progress_cache.keys())[:MAX_TASKS_IN_MEMORY // 5]
                    for k in to_remove:
                        del _progress_cache[k]
                
                _progress_cache[task_id] = deque(maxlen=1000)
            
            _progress_cache[task_id].append(item)
        
        print(f"[PROGRESS] task={task_id}, seq={sequence_id}, phase={phase}, progress={progress}%")
        
        # âœ… æ¨é€å®æ—¶è¿›åº¦ï¼ˆæ•è·ä»»ä½•å¼‚å¸¸ï¼Œä¸å›æ»šäº‹åŠ¡ï¼Œä»…è®°æ—¥å¿—ï¼‰
        if task_id in self.connections and self.connections[task_id]:
            failed_sids = []
            for sid in self.connections[task_id]:
                try:
                    await self.sio.emit('progress', item, room=sid)
                except Exception as e:
                    # âœ… åŠ å›ºï¼šä»…è®°å½•æ—¥å¿—ï¼Œä¸å½±å“ä»»åŠ¡æµç¨‹
                    print(f"[WS] âš ï¸ æ¨é€è¿›åº¦å¤±è´¥ï¼ˆä¸å½±å“ä»»åŠ¡ï¼‰: {sid}, {e}")
                    failed_sids.append(sid)
            
            # æ¸…ç†å¤±è´¥çš„è¿æ¥
            for sid in failed_sids:
                self.connections[task_id].discard(sid)
                if sid in self.sid_to_tasks:
                    self.sid_to_tasks[sid].discard(task_id)
            
            if failed_sids and not self.connections[task_id]:
                del self.connections[task_id]
        else:
            print(f"[WS] âš ï¸  No active connections for {task_id}, progress cached")

    async def get_full_progress(self, task_id: str) -> List[Dict]:
        """è·å–ä»»åŠ¡å®Œæ•´è¿›åº¦å†å²"""
        if USE_REDIS:
            # Redis LRANGE
            items = await redis_client.lrange(f"progress:{task_id}", 0, -1)
            return [json.loads(item) for item in reversed(items)]
        else:
            if task_id in _progress_cache:
                return list(_progress_cache[task_id])
            return []

    async def emit_ai_message(self, task_id: str, actor: str, content: str):
        """æ¨é€AIæ¶ˆæ¯"""
        if task_id in self.connections and self.connections[task_id]:
            for sid in self.connections[task_id]:
                try:
                    await self.sio.emit('ai_message', {
                        'actor': actor,
                        'content': content
                    }, room=sid)
                except Exception as e:
                    print(f"[WS] âŒ Failed to emit ai_message to {sid}: {e}")
    
    async def emit_complete(self, task_id: str, output: Dict):
        """æ¨é€å®Œæˆæ¶ˆæ¯ + ç¼“å­˜äº‹ä»¶"""
        print(f"[WS] ğŸ“¢ Emitting complete for task {task_id}")
        
        complete_data = {'output': output}
        
        # âœ… ç¼“å­˜completeäº‹ä»¶ï¼ˆ5åˆ†é’ŸTTLï¼‰
        if not USE_REDIS:
            _completion_cache[task_id] = complete_data
        
        # æ¨é€ç»™å½“å‰è¿æ¥
        if task_id in self.connections and self.connections[task_id]:
            for sid in self.connections[task_id]:
                try:
                    await self.sio.emit('complete', complete_data, room=sid)
                    print(f"[WS] âœ… Emitted complete to {sid}")
                except Exception as e:
                    print(f"[WS] âŒ Failed to emit complete to {sid}: {e}")
        else:
            print(f"[WS] âš ï¸  No active connections, complete event cached")
        
        # âœ… å»¶è¿Ÿæ¸…ç†ç¼“å­˜ï¼ˆ5åˆ†é’Ÿåï¼‰
        asyncio.create_task(self._delayed_cleanup(task_id))
    
    async def _delayed_cleanup(self, task_id: str):
        """å»¶è¿Ÿæ¸…ç†ç¼“å­˜"""
        await asyncio.sleep(CACHE_CLEANUP_DELAY)
        
        if USE_REDIS:
            await redis_client.delete(f"progress:{task_id}")
            await redis_client.delete(f"seq:{task_id}")
        else:
            _progress_cache.pop(task_id, None)
            _completion_cache.pop(task_id, None)
        
        print(f"[CLEANUP] æ¸…ç†ä»»åŠ¡ç¼“å­˜: {task_id}")
    
    async def emit_error(self, task_id: str, error: str):
        """æ¨é€é”™è¯¯æ¶ˆæ¯"""
        if task_id in self.connections and self.connections[task_id]:
            for sid in self.connections[task_id]:
                try:
                    await self.sio.emit('error', {'error': error}, room=sid)
                except Exception as e:
                    print(f"[WS] âŒ Failed to emit error to {sid}: {e}")
    
    def has_active_connections(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰æ´»è·ƒè¿æ¥"""
        return task_id in self.connections and len(self.connections[task_id]) > 0
    
    async def wait_for_connection(self, task_id: str, timeout: float = 30.0) -> bool:
        """
        ç­‰å¾…WebSocketè¿æ¥å»ºç«‹
        
        ä½¿ç”¨ asyncio.Event é¿å…è½®è¯¢ï¼Œæ›´é«˜æ•ˆ
        """
        print(f"[WS] â³ Waiting for connection to task {task_id} (timeout: {timeout}s)")
        
        # å¦‚æœå·²ç»æœ‰è¿æ¥ï¼Œç«‹å³è¿”å›
        if self.has_active_connections(task_id):
            print(f"[WS] âœ… Connection already active for task {task_id}")
            return True
        
        # åˆ›å»ºæˆ–è·å–äº‹ä»¶
        if task_id not in self._connection_events:
            self._connection_events[task_id] = asyncio.Event()
        
        try:
            # ç­‰å¾…äº‹ä»¶è§¦å‘ï¼ˆå¸¦è¶…æ—¶ï¼‰
            await asyncio.wait_for(
                self._connection_events[task_id].wait(),
                timeout=timeout
            )
            print(f"[WS] âœ… Connection established for task {task_id}")
            return True
        except asyncio.TimeoutError:
            print(f"[WS] âš ï¸  Connection timeout for task {task_id}")
            return False

# åˆ›å»ºå…¨å±€å®ä¾‹
socket_manager = SocketManager()
